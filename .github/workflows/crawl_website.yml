name: Crawl Website and Save as JSON

on:
  push:
  workflow_dispatch:
  schedule:
    - cron:  '6,26,46 * * * *' # every twenty minutes
jobs:
  crawl_and_save:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y python3 python3-pip
        pip3 install requests

    - name: Crawl Website and Save as JSON
      run: |
        python3 crawl_and_save.py  # Aquí deberás escribir el script para acceder a la página y guardar el contenido como JSON
